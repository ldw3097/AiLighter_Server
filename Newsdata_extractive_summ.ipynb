{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"fOzvp34IZQ13"},"outputs":[],"source":["# Bertsum directory chdir\n","import os\n","os.chdir('/home/dongwon/korbertsum/src')"]},{"cell_type":"markdown","metadata":{"id":"gwxwDqcMsIaA"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"ryPPxFlnq2yw"},"source":["**Arguments**\n","\n","-mode train (train, validate, test) # 학습 모드 설정\n","\n","-encoder classifier (classifier, transformer, RNN) # 학습 방법 설정\n","\n","-dropout 0.1 # dropout rate\n","\n","-bert_data_path ../bert_data/korean # bert.pt파일 저장되어있는 경로(pt파일 앞의 단어까지 경로에 쓸 것)\n","\n","-model_path ../models/bert_classifier_sample # train의 경우 학습된 모델 저장\n","\n","-visible_gpus 0 # -1일 경우 cpu, 0이상일 경우 cuda 사용"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"za8H-D8aZrP0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023-09-15 11:57:36,341 INFO] Device ID 0\n","[2023-09-15 11:57:36,341 INFO] Device cuda\n","[2023-09-15 11:57:36,469 INFO] loading archive file /home/dongwon/001_bert_morp_pytorch\n","[2023-09-15 11:57:36,469 INFO] Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30349\n","}\n","\n","[2023-09-15 11:57:37,630 INFO] Summarizer(\n","  (bert): Bert(\n","    (model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30349, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): BertLayerNorm()\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (encoder): TransformerInterEncoder(\n","    (pos_emb): PositionalEncoding(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer_inter): ModuleList(\n","      (0-1): 2 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n","          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=768, out_features=512, bias=True)\n","          (w_2): Linear(in_features=512, out_features=768, bias=True)\n","          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","    (wo): Linear(in_features=768, out_features=1, bias=True)\n","    (sigmoid): Sigmoid()\n","  )\n",")\n","gpu_rank 0\n","[2023-09-15 11:57:37,633 INFO] * number of parameters: 115657985\n","[2023-09-15 11:57:37,633 INFO] Start training...\n","[2023-09-15 11:57:37,633 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:57:37,635 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:57:41,881 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:57:41,883 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:57:44,384 INFO] Step 50/ 1000; xent: 10.78; lr: 0.0000001;  10 docs/s;      7 sec\n","[2023-09-15 11:57:45,825 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:57:45,827 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:57:49,761 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:57:49,763 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:57:50,917 INFO] Step 100/ 1000; xent: 8.81; lr: 0.0000003;  10 docs/s;     13 sec\n","[2023-09-15 11:57:53,729 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:57:53,731 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:57:57,317 INFO] Step 150/ 1000; xent: 6.70; lr: 0.0000004;  10 docs/s;     20 sec\n","[2023-09-15 11:57:57,660 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:57:57,662 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:01,547 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:01,549 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:03,742 INFO] Step 200/ 1000; xent: 6.25; lr: 0.0000006;  11 docs/s;     26 sec\n","[2023-09-15 11:58:05,458 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:05,460 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:09,353 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:09,355 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:09,990 INFO] Step 250/ 1000; xent: 6.26; lr: 0.0000007;  10 docs/s;     32 sec\n","[2023-09-15 11:58:13,281 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:13,284 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:16,328 INFO] Step 300/ 1000; xent: 6.04; lr: 0.0000008;  11 docs/s;     39 sec\n","[2023-09-15 11:58:17,187 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:17,189 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:21,097 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:21,099 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:22,438 INFO] Step 350/ 1000; xent: 5.87; lr: 0.0000010;  10 docs/s;     45 sec\n","[2023-09-15 11:58:25,000 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:25,002 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:28,845 INFO] Step 400/ 1000; xent: 5.54; lr: 0.0000011;  11 docs/s;     51 sec\n","[2023-09-15 11:58:28,912 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:28,914 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:32,835 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:32,837 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:34,968 INFO] Step 450/ 1000; xent: 5.71; lr: 0.0000013;  10 docs/s;     57 sec\n","[2023-09-15 11:58:36,753 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:36,755 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:40,640 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:40,642 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:41,394 INFO] Step 500/ 1000; xent: 5.20; lr: 0.0000014;  11 docs/s;     64 sec\n","[2023-09-15 11:58:44,582 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:44,584 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:47,612 INFO] Step 550/ 1000; xent: 5.26; lr: 0.0000015;  10 docs/s;     70 sec\n","[2023-09-15 11:58:48,489 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:48,491 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:52,382 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:52,384 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:58:53,895 INFO] Step 600/ 1000; xent: 5.15; lr: 0.0000017;  10 docs/s;     76 sec\n","[2023-09-15 11:58:56,259 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:58:56,261 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:00,131 INFO] Step 650/ 1000; xent: 4.74; lr: 0.0000018;  11 docs/s;     82 sec\n","[2023-09-15 11:59:00,198 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:00,201 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:04,089 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:04,091 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:06,419 INFO] Step 700/ 1000; xent: 4.93; lr: 0.0000020;  10 docs/s;     89 sec\n","[2023-09-15 11:59:07,946 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:07,949 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:11,853 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:11,855 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:12,882 INFO] Step 750/ 1000; xent: 4.62; lr: 0.0000021;  11 docs/s;     95 sec\n","[2023-09-15 11:59:15,779 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:15,781 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:19,008 INFO] Step 800/ 1000; xent: 4.19; lr: 0.0000022;  10 docs/s;    101 sec\n","[2023-09-15 11:59:19,714 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:19,716 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:23,622 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:23,624 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:25,144 INFO] Step 850/ 1000; xent: 3.78; lr: 0.0000024;  10 docs/s;    108 sec\n","[2023-09-15 11:59:27,499 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:27,501 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:31,411 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:31,414 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:31,499 INFO] Step 900/ 1000; xent: 3.14; lr: 0.0000025;  11 docs/s;    114 sec\n","[2023-09-15 11:59:35,302 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:35,304 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:37,802 INFO] Step 950/ 1000; xent: 2.16; lr: 0.0000027;  11 docs/s;    120 sec\n","[2023-09-15 11:59:39,203 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:39,205 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:43,099 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:43,101 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n","[2023-09-15 11:59:44,146 INFO] Step 1000/ 1000; xent: 1.30; lr: 0.0000028;  10 docs/s;    127 sec\n","[2023-09-15 11:59:44,148 INFO] Saving checkpoint /home/dongwon/korbertsum/models/bert_classifier/model_step_1000.pt\n","[2023-09-15 11:59:44,933 INFO] Loading train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt\n","[2023-09-15 11:59:44,935 INFO] Loaded train dataset from /home/dongwon/korbertsum/bert_data_my/korean.train.1.bert.pt, number of examples: 41\n"]}],"source":["!python train.py -mode train -encoder transformer -dropout 0.1 -bert_data_path /home/dongwon/korbertsum/bert_data/korean -model_path /home/dongwon/korbertsum/models/bert_classifier -lr 2e-3 -visible_gpus 0 -gpu_ranks 0 -world_size 1 -report_every 50 -save_checkpoint_steps 1000 -batch_size 1000 -decay_method noam -train_steps 1000 -accum_count 1 -log_file /home/dongwon/korbertsum/logs/bert_classifier -use_interval true -warmup_steps 8000 -bert_model /home/dongwon/001_bert_morp_pytorch -bert_config_path /home/dongwon/001_bert_morp_pytorch/bert_config.json -temp_dir ."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uW5ogvPn-FvO"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023-09-15 12:00:04,025 INFO] Loading checkpoint from /home/dongwon/korbertsum/models/bert_classifier/model_step_1000.pt\n","Namespace(encoder='transformer', mode='validate', bert_data_path='/home/dongwon/korbertsum/bert_data_my/korean', model_path='/home/dongwon/korbertsum/models/bert_classifier', result_path='/home/dongwon/korbertsum/results/korean', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=1000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/home/dongwon/korbertsum/logs/bert_classifier', dataset='', seed=666, bert_model='/home/dongwon/001_bert_morp_pytorch', test_all=False, test_from='', train_from='', report_rouge=True, block_trigram=True)\n","[2023-09-15 12:00:04,276 INFO] loading archive file /home/dongwon/001_bert_morp_pytorch\n","[2023-09-15 12:00:04,276 INFO] Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30349\n","}\n","\n","[2023-09-15 12:00:05,571 INFO] Loading valid dataset from /home/dongwon/korbertsum/bert_data_my/korean.valid.0.bert.pt\n","[2023-09-15 12:00:05,571 INFO] Loaded valid dataset from /home/dongwon/korbertsum/bert_data_my/korean.valid.0.bert.pt, number of examples: 5\n","gpu_rank 0\n","[2023-09-15 12:00:05,573 INFO] * number of parameters: 115657985\n","[2023-09-15 12:00:05,955 INFO] Validation xent: 9.2588 at step 1000\n","[2023-09-15 12:00:05,965 INFO] Loading checkpoint from /home/dongwon/korbertsum/models/bert_classifier/model_step_1000.pt\n","Namespace(encoder='transformer', mode='validate', bert_data_path='/home/dongwon/korbertsum/bert_data_my/korean', model_path='/home/dongwon/korbertsum/models/bert_classifier', result_path='/home/dongwon/korbertsum/results/korean', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=1000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/home/dongwon/korbertsum/logs/bert_classifier', dataset='', seed=666, bert_model='/home/dongwon/001_bert_morp_pytorch', test_all=False, test_from='', train_from='', report_rouge=True, block_trigram=True)\n","[2023-09-15 12:00:06,171 INFO] loading archive file /home/dongwon/001_bert_morp_pytorch\n","[2023-09-15 12:00:06,171 INFO] Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30349\n","}\n","\n","[2023-09-15 12:00:06,864 INFO] Loading test dataset from /home/dongwon/korbertsum/bert_data_my/korean.test.0.bert.pt\n","[2023-09-15 12:00:06,864 INFO] Loaded test dataset from /home/dongwon/korbertsum/bert_data_my/korean.test.0.bert.pt, number of examples: 6\n","gpu_rank 0\n","[2023-09-15 12:00:06,866 INFO] * number of parameters: 115657985\n","6\n","6\n","2023-09-15 12:00:07,080 [MainThread  ] [INFO ]  Writing summaries.\n","[2023-09-15 12:00:07,080 INFO] Writing summaries.\n","2023-09-15 12:00:07,080 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpp0h6quvm/system and model files to ../temp/tmpp0h6quvm/model.\n","[2023-09-15 12:00:07,080 INFO] Processing summaries. Saving system files to ../temp/tmpp0h6quvm/system and model files to ../temp/tmpp0h6quvm/model.\n","2023-09-15 12:00:07,080 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2023-09-15-12-00-07/candidate/.\n","[2023-09-15 12:00:07,080 INFO] Processing files in ../temp/rouge-tmp-2023-09-15-12-00-07/candidate/.\n","2023-09-15 12:00:07,080 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpp0h6quvm/system.\n","[2023-09-15 12:00:07,080 INFO] Saved processed files to ../temp/tmpp0h6quvm/system.\n","2023-09-15 12:00:07,080 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2023-09-15-12-00-07/reference/.\n","[2023-09-15 12:00:07,080 INFO] Processing files in ../temp/rouge-tmp-2023-09-15-12-00-07/reference/.\n","2023-09-15 12:00:07,081 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpp0h6quvm/model.\n","[2023-09-15 12:00:07,081 INFO] Saved processed files to ../temp/tmpp0h6quvm/model.\n","2023-09-15 12:00:07,081 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpzv6684t1/rouge_conf.xml\n","[2023-09-15 12:00:07,081 INFO] Written ROUGE configuration to ../temp/tmpzv6684t1/rouge_conf.xml\n","2023-09-15 12:00:07,081 [MainThread  ] [INFO ]  Running ROUGE with command /home/dongwon/rouge/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/dongwon/rouge/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpzv6684t1/rouge_conf.xml\n","[2023-09-15 12:00:07,081 INFO] Running ROUGE with command /home/dongwon/rouge/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/dongwon/rouge/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpzv6684t1/rouge_conf.xml\n","---------------------------------------------\n","1 ROUGE-1 Average_R: 0.68475 (95%-conf.int. 0.51618 - 0.83697)\n","1 ROUGE-1 Average_P: 0.82217 (95%-conf.int. 0.76539 - 0.87931)\n","1 ROUGE-1 Average_F: 0.72222 (95%-conf.int. 0.60822 - 0.81235)\n","---------------------------------------------\n","1 ROUGE-2 Average_R: 0.55592 (95%-conf.int. 0.41233 - 0.71275)\n","1 ROUGE-2 Average_P: 0.67425 (95%-conf.int. 0.57873 - 0.76148)\n","1 ROUGE-2 Average_F: 0.58644 (95%-conf.int. 0.49018 - 0.69266)\n","---------------------------------------------\n","1 ROUGE-L Average_R: 0.65743 (95%-conf.int. 0.49635 - 0.81790)\n","1 ROUGE-L Average_P: 0.79074 (95%-conf.int. 0.72806 - 0.85393)\n","1 ROUGE-L Average_F: 0.69315 (95%-conf.int. 0.58664 - 0.78780)\n","\n","[2023-09-15 12:00:07,162 INFO] Rouges at step 1000 \n",">> ROUGE-F(1/2/3/l): 72.22/58.64/69.31\n","ROUGE-R(1/2/3/l): 68.47/55.59/65.74\n","\n","[2023-09-15 12:00:07,162 INFO] Validation xent: 9.74926 at step 1000\n","^C\n","Traceback (most recent call last):\n","  File \"/home/dongwon/korbertsum/src/train.py\", line 369, in <module>\n","    wait_and_validate(args, device_id)\n","  File \"/home/dongwon/korbertsum/src/train.py\", line 141, in wait_and_validate\n","    cp_files = sorted(glob.glob(os.path.join(args.model_path, 'model_step_*.pt')))\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/home/dongwon/anaconda3/envs/ai/lib/python3.11/glob.py\", line 28, in glob\n","    return list(iglob(pathname, root_dir=root_dir, dir_fd=dir_fd, recursive=recursive,\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/home/dongwon/anaconda3/envs/ai/lib/python3.11/glob.py\", line 97, in _iglob\n","    for name in glob_in_dir(_join(root_dir, dirname), basename, dir_fd, dironly,\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/home/dongwon/anaconda3/envs/ai/lib/python3.11/glob.py\", line 106, in _glob1\n","    names = _listdir(dirname, dir_fd, dironly)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/home/dongwon/anaconda3/envs/ai/lib/python3.11/glob.py\", line 177, in _listdir\n","    return list(it)\n","           ^^^^^^^^\n","  File \"/home/dongwon/anaconda3/envs/ai/lib/python3.11/glob.py\", line 166, in _iterdir\n","    yield entry.name\n","KeyboardInterrupt\n"]}],"source":["!python train.py -mode validate -bert_data_path /home/dongwon/korbertsum/bert_data/korean -model_path /home/dongwon/korbertsum/models/bert_classifier  -visible_gpus 0  -gpu_ranks 0 -batch_size 1000  -log_file /home/dongwon/korbertsum/logs/bert_classifier  -result_path /home/dongwon/korbertsum/results/korean -bert_model /home/dongwon/001_bert_morp_pytorch"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"WoaKzondr8jd"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023-09-12 19:15:10,617 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1000.pt\n","Namespace(encoder='classifier', mode='test', bert_data_path='/content/bert_data/korean', model_path='../models/bert_classifier', result_path='../results/korean', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=1000, use_interval=True, hidden_size=128, ff_size=512, heads=4, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='../logs/bert_classifier', dataset='', seed=666, bert_model='/content/001_bert_morp_pytorch', test_all=False, test_from='../models/bert_classifier/model_step_1000.pt', train_from='', report_rouge=True, block_trigram=True)\n","[2023-09-12 19:15:10,866 ERROR] Model name '/content/001_bert_morp_pytorch' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed '/content/001_bert_morp_pytorch' was a path or url but couldn't find any file associated to this path or url.\n","Traceback (most recent call last):\n","  File \"/home/dongwon/korbertsum/src/train.py\", line 380, in <module>\n","    test(args, device_id, cp, step)\n","  File \"/home/dongwon/korbertsum/src/train.py\", line 209, in test\n","    model.load_cp(checkpoint)\n","  File \"/home/dongwon/korbertsum/src/models/model_builder.py\", line 90, in load_cp\n","    self.load_state_dict(pt['model'], strict=True)\n","  File \"/home/dongwon/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for Summarizer:\n","\tUnexpected key(s) in state_dict: \"bert.model.embeddings.word_embeddings.weight\", \"bert.model.embeddings.position_embeddings.weight\", \"bert.model.embeddings.token_type_embeddings.weight\", \"bert.model.embeddings.LayerNorm.weight\", \"bert.model.embeddings.LayerNorm.bias\", \"bert.model.encoder.layer.0.attention.self.query.weight\", \"bert.model.encoder.layer.0.attention.self.query.bias\", \"bert.model.encoder.layer.0.attention.self.key.weight\", \"bert.model.encoder.layer.0.attention.self.key.bias\", \"bert.model.encoder.layer.0.attention.self.value.weight\", \"bert.model.encoder.layer.0.attention.self.value.bias\", \"bert.model.encoder.layer.0.attention.output.dense.weight\", \"bert.model.encoder.layer.0.attention.output.dense.bias\", \"bert.model.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.0.intermediate.dense.weight\", \"bert.model.encoder.layer.0.intermediate.dense.bias\", \"bert.model.encoder.layer.0.output.dense.weight\", \"bert.model.encoder.layer.0.output.dense.bias\", \"bert.model.encoder.layer.0.output.LayerNorm.weight\", \"bert.model.encoder.layer.0.output.LayerNorm.bias\", \"bert.model.encoder.layer.1.attention.self.query.weight\", \"bert.model.encoder.layer.1.attention.self.query.bias\", \"bert.model.encoder.layer.1.attention.self.key.weight\", \"bert.model.encoder.layer.1.attention.self.key.bias\", \"bert.model.encoder.layer.1.attention.self.value.weight\", \"bert.model.encoder.layer.1.attention.self.value.bias\", \"bert.model.encoder.layer.1.attention.output.dense.weight\", \"bert.model.encoder.layer.1.attention.output.dense.bias\", \"bert.model.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.1.intermediate.dense.weight\", \"bert.model.encoder.layer.1.intermediate.dense.bias\", \"bert.model.encoder.layer.1.output.dense.weight\", \"bert.model.encoder.layer.1.output.dense.bias\", \"bert.model.encoder.layer.1.output.LayerNorm.weight\", \"bert.model.encoder.layer.1.output.LayerNorm.bias\", \"bert.model.encoder.layer.2.attention.self.query.weight\", \"bert.model.encoder.layer.2.attention.self.query.bias\", \"bert.model.encoder.layer.2.attention.self.key.weight\", \"bert.model.encoder.layer.2.attention.self.key.bias\", \"bert.model.encoder.layer.2.attention.self.value.weight\", \"bert.model.encoder.layer.2.attention.self.value.bias\", \"bert.model.encoder.layer.2.attention.output.dense.weight\", \"bert.model.encoder.layer.2.attention.output.dense.bias\", \"bert.model.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.2.intermediate.dense.weight\", \"bert.model.encoder.layer.2.intermediate.dense.bias\", \"bert.model.encoder.layer.2.output.dense.weight\", \"bert.model.encoder.layer.2.output.dense.bias\", \"bert.model.encoder.layer.2.output.LayerNorm.weight\", \"bert.model.encoder.layer.2.output.LayerNorm.bias\", \"bert.model.encoder.layer.3.attention.self.query.weight\", \"bert.model.encoder.layer.3.attention.self.query.bias\", \"bert.model.encoder.layer.3.attention.self.key.weight\", \"bert.model.encoder.layer.3.attention.self.key.bias\", \"bert.model.encoder.layer.3.attention.self.value.weight\", \"bert.model.encoder.layer.3.attention.self.value.bias\", \"bert.model.encoder.layer.3.attention.output.dense.weight\", \"bert.model.encoder.layer.3.attention.output.dense.bias\", \"bert.model.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.3.intermediate.dense.weight\", \"bert.model.encoder.layer.3.intermediate.dense.bias\", \"bert.model.encoder.layer.3.output.dense.weight\", \"bert.model.encoder.layer.3.output.dense.bias\", \"bert.model.encoder.layer.3.output.LayerNorm.weight\", \"bert.model.encoder.layer.3.output.LayerNorm.bias\", \"bert.model.encoder.layer.4.attention.self.query.weight\", \"bert.model.encoder.layer.4.attention.self.query.bias\", \"bert.model.encoder.layer.4.attention.self.key.weight\", \"bert.model.encoder.layer.4.attention.self.key.bias\", \"bert.model.encoder.layer.4.attention.self.value.weight\", \"bert.model.encoder.layer.4.attention.self.value.bias\", \"bert.model.encoder.layer.4.attention.output.dense.weight\", \"bert.model.encoder.layer.4.attention.output.dense.bias\", \"bert.model.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.4.intermediate.dense.weight\", \"bert.model.encoder.layer.4.intermediate.dense.bias\", \"bert.model.encoder.layer.4.output.dense.weight\", \"bert.model.encoder.layer.4.output.dense.bias\", \"bert.model.encoder.layer.4.output.LayerNorm.weight\", \"bert.model.encoder.layer.4.output.LayerNorm.bias\", \"bert.model.encoder.layer.5.attention.self.query.weight\", \"bert.model.encoder.layer.5.attention.self.query.bias\", \"bert.model.encoder.layer.5.attention.self.key.weight\", \"bert.model.encoder.layer.5.attention.self.key.bias\", \"bert.model.encoder.layer.5.attention.self.value.weight\", \"bert.model.encoder.layer.5.attention.self.value.bias\", \"bert.model.encoder.layer.5.attention.output.dense.weight\", \"bert.model.encoder.layer.5.attention.output.dense.bias\", \"bert.model.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.5.intermediate.dense.weight\", \"bert.model.encoder.layer.5.intermediate.dense.bias\", \"bert.model.encoder.layer.5.output.dense.weight\", \"bert.model.encoder.layer.5.output.dense.bias\", \"bert.model.encoder.layer.5.output.LayerNorm.weight\", \"bert.model.encoder.layer.5.output.LayerNorm.bias\", \"bert.model.encoder.layer.6.attention.self.query.weight\", \"bert.model.encoder.layer.6.attention.self.query.bias\", \"bert.model.encoder.layer.6.attention.self.key.weight\", \"bert.model.encoder.layer.6.attention.self.key.bias\", \"bert.model.encoder.layer.6.attention.self.value.weight\", \"bert.model.encoder.layer.6.attention.self.value.bias\", \"bert.model.encoder.layer.6.attention.output.dense.weight\", \"bert.model.encoder.layer.6.attention.output.dense.bias\", \"bert.model.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.6.intermediate.dense.weight\", \"bert.model.encoder.layer.6.intermediate.dense.bias\", \"bert.model.encoder.layer.6.output.dense.weight\", \"bert.model.encoder.layer.6.output.dense.bias\", \"bert.model.encoder.layer.6.output.LayerNorm.weight\", \"bert.model.encoder.layer.6.output.LayerNorm.bias\", \"bert.model.encoder.layer.7.attention.self.query.weight\", \"bert.model.encoder.layer.7.attention.self.query.bias\", \"bert.model.encoder.layer.7.attention.self.key.weight\", \"bert.model.encoder.layer.7.attention.self.key.bias\", \"bert.model.encoder.layer.7.attention.self.value.weight\", \"bert.model.encoder.layer.7.attention.self.value.bias\", \"bert.model.encoder.layer.7.attention.output.dense.weight\", \"bert.model.encoder.layer.7.attention.output.dense.bias\", \"bert.model.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.7.intermediate.dense.weight\", \"bert.model.encoder.layer.7.intermediate.dense.bias\", \"bert.model.encoder.layer.7.output.dense.weight\", \"bert.model.encoder.layer.7.output.dense.bias\", \"bert.model.encoder.layer.7.output.LayerNorm.weight\", \"bert.model.encoder.layer.7.output.LayerNorm.bias\", \"bert.model.encoder.layer.8.attention.self.query.weight\", \"bert.model.encoder.layer.8.attention.self.query.bias\", \"bert.model.encoder.layer.8.attention.self.key.weight\", \"bert.model.encoder.layer.8.attention.self.key.bias\", \"bert.model.encoder.layer.8.attention.self.value.weight\", \"bert.model.encoder.layer.8.attention.self.value.bias\", \"bert.model.encoder.layer.8.attention.output.dense.weight\", \"bert.model.encoder.layer.8.attention.output.dense.bias\", \"bert.model.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.8.intermediate.dense.weight\", \"bert.model.encoder.layer.8.intermediate.dense.bias\", \"bert.model.encoder.layer.8.output.dense.weight\", \"bert.model.encoder.layer.8.output.dense.bias\", \"bert.model.encoder.layer.8.output.LayerNorm.weight\", \"bert.model.encoder.layer.8.output.LayerNorm.bias\", \"bert.model.encoder.layer.9.attention.self.query.weight\", \"bert.model.encoder.layer.9.attention.self.query.bias\", \"bert.model.encoder.layer.9.attention.self.key.weight\", \"bert.model.encoder.layer.9.attention.self.key.bias\", \"bert.model.encoder.layer.9.attention.self.value.weight\", \"bert.model.encoder.layer.9.attention.self.value.bias\", \"bert.model.encoder.layer.9.attention.output.dense.weight\", \"bert.model.encoder.layer.9.attention.output.dense.bias\", \"bert.model.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.9.intermediate.dense.weight\", \"bert.model.encoder.layer.9.intermediate.dense.bias\", \"bert.model.encoder.layer.9.output.dense.weight\", \"bert.model.encoder.layer.9.output.dense.bias\", \"bert.model.encoder.layer.9.output.LayerNorm.weight\", \"bert.model.encoder.layer.9.output.LayerNorm.bias\", \"bert.model.encoder.layer.10.attention.self.query.weight\", \"bert.model.encoder.layer.10.attention.self.query.bias\", \"bert.model.encoder.layer.10.attention.self.key.weight\", \"bert.model.encoder.layer.10.attention.self.key.bias\", \"bert.model.encoder.layer.10.attention.self.value.weight\", \"bert.model.encoder.layer.10.attention.self.value.bias\", \"bert.model.encoder.layer.10.attention.output.dense.weight\", \"bert.model.encoder.layer.10.attention.output.dense.bias\", \"bert.model.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.10.intermediate.dense.weight\", \"bert.model.encoder.layer.10.intermediate.dense.bias\", \"bert.model.encoder.layer.10.output.dense.weight\", \"bert.model.encoder.layer.10.output.dense.bias\", \"bert.model.encoder.layer.10.output.LayerNorm.weight\", \"bert.model.encoder.layer.10.output.LayerNorm.bias\", \"bert.model.encoder.layer.11.attention.self.query.weight\", \"bert.model.encoder.layer.11.attention.self.query.bias\", \"bert.model.encoder.layer.11.attention.self.key.weight\", \"bert.model.encoder.layer.11.attention.self.key.bias\", \"bert.model.encoder.layer.11.attention.self.value.weight\", \"bert.model.encoder.layer.11.attention.self.value.bias\", \"bert.model.encoder.layer.11.attention.output.dense.weight\", \"bert.model.encoder.layer.11.attention.output.dense.bias\", \"bert.model.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.model.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.model.encoder.layer.11.intermediate.dense.weight\", \"bert.model.encoder.layer.11.intermediate.dense.bias\", \"bert.model.encoder.layer.11.output.dense.weight\", \"bert.model.encoder.layer.11.output.dense.bias\", \"bert.model.encoder.layer.11.output.LayerNorm.weight\", \"bert.model.encoder.layer.11.output.LayerNorm.bias\", \"bert.model.pooler.dense.weight\", \"bert.model.pooler.dense.bias\". \n"]}],"source":["!python train.py -mode test -bert_data_path /content/bert_data/korean -model_path ../models/bert_classifier  -visible_gpus 0  -gpu_ranks 0 -batch_size 1000  -log_file ../logs/bert_classifier  -result_path ../results/korean -bert_model /content/001_bert_morp_pytorch -test_from ../models/bert_classifier/model_step_1000.pt"]},{"cell_type":"markdown","metadata":{"id":"rIZruOeCsL_5"},"source":["# Test"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Fr5Ht2L0pV5J"},"outputs":[],"source":["with open('/home/dongwon/korbertsum/results/korean_step1000.gold','r') as f:\n","    gold = f.readlines()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0ff8k_UYpupz"},"outputs":[],"source":["with open('/home/dongwon/korbertsum/results/korean_step1000.candidate','r') as f:\n","    candidate = f.readlines()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ieg_5YynplZd"},"outputs":[{"data":{"text/plain":["'인천/NNP 은/JX 산둥성/NNP 을/JKO 비롯하/VV 어/EC 산둥성/NNP 주요/NNG 도시/NNG 이/VCP ㄴ/ETM 칭다오/NNP (/SS 靑島/SH )/SS ·/SP 옌타이/NNP (/SS 煙臺/SH )/SS 시/NNG 와/JC 우호/NNG 도시/NNG 관계/NNG 이/VCP 다/EF<q>또/MAG 미래/NNG 인/NNG 적/XSN 자산/NNG 으로서/JKB 청/NNG 소년/NNG 및/MAJ 학생/NNG 들/XSN 의/JKG 교류/NNG 활성/NNG 화/XSN 필요/NNG 성/XSN 도/JX 강조/NNG 하/XSV 었/EP 다/EF<q>박남춘/NNP 시장/NNG 은/JX \"/SS 두/MM 지역/NNG 의/JKG 상생/NNG 발전/NNG 을/JKO 위하/VV ㄴ/ETM 기술/NNG 협력/NNG ,/SP 상호/NNG 인증/NNG ,/SP 문화/NNG ·/SP 관광/NNG 융합/NNG 콘텐츠/NNG 개발/NNG 및/MAJ 한중/NNP FTA/SL 지방/NNG 경제/NNG 협력/NNG 시범/NNG 사업/NNG 의/JKG 성과/NNG 를/JKO 발전/NNG 시키/XSV 어/EC 두/MM 나라/NNG 간/NNB FTA/SL 선도/NNG 지역/NNG 의/JKG 역할/NNG 을/JKO 지속/NNG 적/XSN 으로/JKB 실천/NNG 하/XSV ㄹ/ETM 필요/NNG 가/JKS 있/VA 다/EF \"/SS 며/EC \"/SS 미래/NNG 지향/NNG 적/XSN 가치/NNG 창출/NNG 을/JKO 위하/VV 어/EC 공동/NNG 과제/NNG 를/JKO 발굴/NNG 하/XSV 고/EC 추진/NNG 하/XSV 어/EC 나가/VX 자/EF \"/SS 고/JKQ 말/NNG 하/XSV 었/EP 다/EF\\n'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# 라벨 데이터\n","gold[3]"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"V4JZJNYXpz2X"},"outputs":[{"data":{"text/plain":["'12/SN 일/NNB 시/NNG 에/JKB 따르/VV 면/EC 박남춘/NNP 인천/NNP 시장/NNG 은/JX 이날/NNG 산둥성/NNP 을/JKO 방문/NNG 하/XSV 어/EC 지난/NNG (/SS 濟南/SH )/SS 시/NNG 왕중린/NNP (/SS 王忠林/SH )/SS 서기/NNG 와/JC 산둥성/NNP 류자이/NNP (/SS 劉家義/SH )/SS 서기/NNG 를/JKO 차례/NNG 로/JKB 접견/NNG 하/XSV 며/EC 상호/NNG 협력/NNG 발전/NNG 방안/NNG 을/JKO 논의/NNG 하/XSV 었/EP 다/EF<q>박/NNP 시장/NNG ,/SP 류자/NNP 이/JKS 서기/NNG 와/JC 접견/NNG 공동/NNG 포럼/NNG ·/SP 청/NNG 소년/NNG 교류/NNG 제안/NNG 인천시/NNP 가/JKS 중국/NNP 산둥/NNP (/SS 山東/SH )/SS 성/NNG 과/JC 우호/NNG 관계/NNG 를/JKO 넘/VV 어/EC ‘/SS 친구/NNG 도시/NNG ’/SS 로/JKB 나아가/VV 는/ETM 첫/MM 발/NNG 을/JKO 내디디/VV 었/EP 다/EF<q>인천/NNP 은/JX 산둥성/NNP 을/JKO 비롯하/VV 어/EC 산둥성/NNP 주요/NNG 도시/NNG 이/VCP ㄴ/ETM 칭다오/NNP (/SS 靑島/SH )/SS ·/SP 옌타이/NNP (/SS 煙臺/SH )/SS 시/NNG 와/JC 우호/NNG 도시/NNG 관계/NNG 이/VCP 다/EF\\n'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# 예측 데이터\n","candidate[3]"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOHi3fjXHKga4urnmSF7c68","collapsed_sections":[],"machine_shape":"hm","name":"Newsdata_extractive_summ.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
