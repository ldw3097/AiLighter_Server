{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/dongwon/korbertsum/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "import distributed\n",
    "from models import data_loader, model_builder\n",
    "from models.data_loader import load_dataset\n",
    "from models.model_builder import Summarizer\n",
    "from prepro.data_builder import format_to_dict\n",
    "from tensorboardX import SummaryWriter\n",
    "from models.reporter import ReportMgr\n",
    "from models.stats import Statistics\n",
    "from others.logging import logger\n",
    "from others.logging import logger, init_logger\n",
    "from models.trainer import build_trainer\n",
    "\n",
    "# bertsum을 위한 파라미터 지정\n",
    "args = easydict.EasyDict({\n",
    "    \"encoder\":'classifier',\n",
    "    \"mode\":'summary',\n",
    "    \"bert_data_path\":'/home/dongwon/korbertsum/bert_data/korean',\n",
    "    \"model_path\":'/home/dongwon/korbertsum/models/bert_classifier',\n",
    "    \"bert_model\":'/home/dongwon/001_bert_morp_pytorch',\n",
    "    \"result_path\":'/home/dongwon/korbertsum/results/korean',\n",
    "    \"temp_dir\":'.',\n",
    "    \"bert_config_path\":'/home/dongwon/001_bert_morp_pytorch/bert_config.json',\n",
    "    \"batch_size\":1000,\n",
    "    \"use_interval\":True,\n",
    "    \"hidden_size\":128,\n",
    "    \"ff_size\":512,\n",
    "    \"heads\":4,\n",
    "    \"inter_layers\":2,\n",
    "    \"rnn_size\":512,\n",
    "    \"param_init\":0,\n",
    "    \"param_init_glorot\":True,\n",
    "    \"dropout\":0.1,\n",
    "    \"optim\":'adam',\n",
    "    \"lr\":2e-3,\n",
    "    \"report_every\":1,\n",
    "    \"save_checkpoint_steps\":5,\n",
    "    \"block_trigram\":True,\n",
    "    \"recall_eval\":False,\n",
    "    \n",
    "    \"accum_count\":1,\n",
    "    \"world_size\":1,\n",
    "    \"visible_gpus\":'-1',\n",
    "    \"gpu_ranks\":'0',\n",
    "    \"log_file\":'/home/dongwon/korbertsum/logs/bert_classifier',\n",
    "    \"test_from\":'/home/dongwon/korbertsum/models/bert_classifier/model_step_40000.pt' # 사용할 fine-tuning된 모델을 따로 지정해야 함\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(args, b_list, device_id, pt, step):\n",
    "\n",
    "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "    if (pt != ''):\n",
    "        test_from = pt\n",
    "    else:\n",
    "        test_from = args.test_from\n",
    "    logger.info('Loading checkpoint from %s' % test_from)\n",
    "    checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\n",
    "    opt = vars(checkpoint['opt'])\n",
    "    for k in opt.keys():\n",
    "        if (k in model_flags):\n",
    "            setattr(args, k, opt[k])\n",
    "    print(args)\n",
    "\n",
    "    config = BertConfig.from_json_file(args.bert_config_path)\n",
    "    model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
    "    model.load_cp(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    test_iter =data_loader.Dataloader(args, _lazy_dataset_loader(b_list),\n",
    "                                  args.batch_size, device,\n",
    "                                  shuffle=False, is_test=True)\n",
    "    trainer = build_trainer(args, device_id, model, None)\n",
    "    result = trainer.summary(test_iter,step)\n",
    "    return result\n",
    "\n",
    "model_flags = ['hidden_size', 'ff_size', 'heads', 'inter_layers','encoder','ff_actv', 'use_interval','rnn_size']\n",
    "def _lazy_dataset_loader(pt_file):\n",
    "    dataset = pt_file\n",
    "    yield dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'src': [2, 7525, 1974, 9, 1, 1, 19, 261, 23, 677, 13, 208, 14, 908, 53, 1383, 1716, 19, 205, 1, 977, 19, 1412, 12, 8, 7, 3, 2, 596, 18, 1, 12, 74, 2259, 911, 1, 3555, 14, 18, 334, 318, 22, 2596, 386, 16, 70, 12, 8, 7, 3, 2, 1, 5865, 1, 1261, 28, 1282, 9, 464, 57, 526, 145, 1, 21, 754, 24, 135, 14, 2862, 498, 12, 94, 1, 432, 318, 526, 7, 1, 3, 2, 1, 1054, 4343, 3938, 9, 1, 195, 208, 19, 908, 23, 1282, 9, 12, 8, 7, 3, 2, 2435, 15, 265, 734, 16, 1267, 4287, 12, 74, 410, 464, 91, 298, 2275, 1, 14, 2413, 9, 1, 55, 38, 12, 8, 7, 3, 2, 5166, 1, 14, 3119, 19, 40, 23, 1, 1, 94, 677, 13, 1, 15, 104, 1, 1, 1, 386, 14, 2413, 9, 12, 8, 7, 3, 2, 1, 3249, 2722, 11, 432, 1120, 22, 452, 15, 1, 17, 231, 24, 2413, 9, 12, 93, 110, 4249, 54, 87, 364, 24, 816, 20, 37, 12, 23, 231, 24, 122, 364, 14, 2322, 4349, 1036, 1, 20, 139, 36, 16, 2722, 11, 1120, 49, 224, 9, 12, 8, 7, 3, 2, 1, 1, 17, 231, 1, 2083, 16, 204, 12, 526, 7, 1, 3, 2, 1, 1054, 47, 461, 145, 1, 754, 24, 1, 4754, 15, 265, 1054, 1, 1953, 524, 1, 3, 2, 191, 24, 6274, 11, 40, 220, 677, 24, 1, 20, 112, 1, 7, 3, 2, 7339, 19, 1, 47, 61, 20, 129, 1, 1, 42, 1, 7866, 1577, 54, 4120, 11, 3023, 9, 23, 17, 1, 14, 1, 19, 92, 851, 1343, 463, 20, 1, 20, 689, 128, 387, 7708, 662, 19, 1412, 12, 8, 7, 3, 2, 1748, 1116, 3862, 977, 15, 12, 137, 17, 677, 18, 231, 386, 27, 102, 1, 191, 13, 1301, 36, 14, 73, 94, 34, 8207, 977, 9, 4893, 61, 12, 8, 7, 3, 2, 1, 19, 911, 689, 45, 195, 1, 28, 1, 45, 1, 1, 19, 2088, 22, 452, 28, 1282, 9, 12, 8, 7, 3, 2, 1865, 19, 689, 45, 344, 755, 1851, 15, 1, 17, 80, 139, 16, 1790, 1, 1267, 318, 1, 422, 94, 588, 14, 261, 12, 8, 7, 3, 2, 1, 19, 1, 689, 23, 37, 22, 397, 677, 76, 1, 16, 219, 12, 8, 7, 3, 2, 1, 1, 145, 4109, 24, 1, 40, 5396, 1, 137, 461, 145, 1, 1, 281, 2026, 7, 1, 3, 2, 677, 56, 4109, 18, 624, 2015, 40, 53, 5732, 4231, 20, 111, 1, 474, 15, 12, 798, 2259, 16, 1, 11, 4858, 40, 22, 33, 103, 12, 8, 7, 3, 2, 1, 7016, 17, 2417, 461, 145, 2435, 14, 4417, 2930, 2597, 9, 94, 1, 42, 96, 40, 10540, 17, 1, 1914, 16, 515, 1, 7, 1, 3, 2, 1, 5028, 17, 1054, 1, 7, 3, 2, 5865, 2330, 1123, 3755, 529, 1082, 219, 118, 40, 1, 145, 2783, 42, 71, 319, 952, 2690, 461, 7, 1, 3, 2, 1, 754, 1, 204, 526, 3], 'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'segs': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], 'clss': [0, 27, 50, 79, 97, 123, 150, 202, 216, 235, 250, 293, 326, 350, 378, 396, 416, 447, 475, 483, 505], 'src_txt': ['각자 구매한 위스키를 들고 K의 차에 타며 이제 어디를 갈까 얘기를 나눴다.', '배는 고팠지만 둘 다 남대문 근처에는 잘 아는 맛집이 없었다.', '', '\"혹시 망원동 쪽으로 이동해도 돼요? 그쪽은 제가 전에 오래 살았어서 맛집 많이 알아요.\"', '흔쾌히 그러자고 대답한 뒤 차를 타고 이동했다.', '주말이라 길이 좀 막혔지만 그래도 5 시쯤 망원동에 도착할 수 있었다.', '동네 끄트머리에 주차를 하고 천천히 걸어서 K의 단골이라는 일본식 화로구이집에 도착했다.', '원래 굉장히 줄을 많이 서는 곳인데, 우리가 도착했을 때 딱 2명 자리가 남아있었고 우리가 그 자리에 앉자마자 바로 뒤이어 사람들이 줄을 서기 시작했다.', '', '\"오, 우리 되게 운이 좋았어요.\"', '\"그러게요? 역시 제가 럭키걸이라 그런 듯!\"', '내가 농담을 하자 K가 웃어 보인다.', '더위를 가시게 해줄 시원한 하이볼 2잔을 주문하고, 화로에 소고기를 한 점씩 올려 구워 먹으며 이런 저런 이야기를 나눴다.', '주로 과거 연애 얘기였는데, K는 우리집에서 본 내 책들에 대해서도 수시로 얘기하곤 했다.', '', '소고기를 다 먹은 뒤 후식으로 귀여운 수제 젤라또를 파는 곳으로 이동했다.', '고기를 먹은 다음 단 음식이라니, 이 사람이 뭘 좀 아는군 싶어서 마음에 들었다.', '젤라또를 야금야금 먹고 있는 데 K에게 카톡이 왔다.', '\"어? Y가 뭐하냐고 묻는데요? 심심한가 보네.\"', 'K와 Y는 형 동생 하며 꽤 친해진 상태였는지 둘이 카톡을 종종 하는 것 같았다.', '', '\"아, 진짜요? 주말에 형한테 연락해서 심심하다고 하다니, 왠지 눈물이 나네요.\"', '\"하하, 그러니까요.', '혹시 J님 괜찮으면 여기 오라고 할까요? 불편하면 안 부르고요.\"', '\"전 좋아요.', 'Y님이야말로 형이랑 둘이 놀고 싶었는데 저 때문에 방해되는 거면 제가 쓰윽 빠져드리겠습니다.\"', '\"오히려 좋아할 거에요.', '그럼 망원동으로 오라고 할게요.\"', 'Y가 오면 술 한잔 더 하겠냐는 K의 제안에 그러자고 했더니 자주 가는 단골 술집이 있다며 안내했다.', '천천히 걸어서 도��하니 Y가 가게 앞에 먼저 와있었다.', '반갑게 인사하고 함께 들어간 술집은 망원동스러운 작은 1인 셰프 술집이었다.', '여자 사장이 혼자 요리하고 서빙하는 매장이었는데, 메뉴판에 없는 메뉴도 즉석으로 만들어주는 심야식당 같은 곳이었다.', '', '\"K? 오랜만이네!\"', '사장님이 K를 알아보곤 반갑게 인사를 해왔다.', '', '\"이사간 뒤로는 이 동네로 잘 안 오게 되더라고요.', '잘 지냈죠?\"', '\"나야 똑같지.', '그런데 이 분들은 처음 보는 분들이네? 어서 와요.\"', '한 눈에도 유쾌하고 밝은 에너지가 넘치는 사장님은 우리에게도 밝게 말을 걸어왔다.', '평소 술을 마시러 다니지 않다보니, 단골을 맞이하는 유쾌한 술집 사장님을 만나게 되어서 왠지 기분이 좋았다.', '안주로 먹을 가게의 시그니쳐 메뉴를 하나 주문하고, 킵해놨었다는 위스키를 꺼내 술을 마셨다.', '', '\"그러고보니 얘가 여자 데리고 온 건 처음이네? 맨날 혼술 하러 오거나 남자 동생들 데리고 와서, 보통 나랑 수다 떨며 노는데.\"', '\"아, 그래요? 의외네요.', '여자들만 잔뜩 데려올 것 같은 이미지인데 말이죠.\"', '내가 농담을 했더니 사장님도 웃으면서 \"맞아 맞아.', '그런 이미지지.', '그런데 여자는 다른 데서 만나는 것 같고, 여긴 안 데려 오더라고.\" 하시며 함께 농담으로 받아주었다.', '', '위스키를 각자 2 잔 정도씩 마신 뒤 K가 제안했다.', '', '\"어때요? 장소 이동해서 한 잔 씩들 더 할래요?\"', 'Y와 나는 둘 다 좋다고 하며, 근처에 어디 아는 데 있냐고 물어봤다.', '', '\"음, 위스키로 계속 마실 거면 밖에서 마시지 말고 우리 집에 가서 마실까요? 밖에서 마시면 비싸잖아요.', '오늘 내가 산 위스키 ���이 마셔요.\"', 'K의 집은 망원동에서 차로 15분 정도 걸리는 거리였다.', '남자 2명과 함께 남자 혼자 사는 자취방에 가서 술이라.', '예전의 나였다면 무서워서 가지 않았을 것 같았다.', ' ', '하지만 지난 예술의전당 벙개 때 K와 나눈 대화, 우리 집에 방문했을 때 나눈 대화, 그리고 오늘까지.', '모임 사람들 중 어쩌다보니 K와 가장 많은 시간을 보냈고 그 과정에서 느낀 건 이상한 짓을 하거나 수상한 행동을 할 사람은 아니라는 거였다.', '물론 사람을 잠깐 보고 어떻게 알겠냐 할 수도 있지만, 난 내 직감과 안목을 믿고 있었다.', ' K도 Y도 나쁜 사람들이 아니다.', '', '대리기사를 불러서 금방 도착한 K의 집은 그의 옷 스타일같은 이미지였다.', '깔끔하고 세련된 느낌.', '40대 중반의 혼자 사는 남자가 이 정도로 잘 해놓고 산다니 신기할 정도였다.', '유행하는 미드센추리 감성의 가구와 조명, 지저분한 곳은 가림막 커튼으로 가려 놓는 센스, 잘 정리된 책장과 곳곳에 배치되어 있는 식물까지.', '여기 사는 사람이 남자가 아니라 여자라고 하는 게 어울릴 지경이었다.', '남자보다 여자가 더 잘 꾸미고 산다는 내 고정관념 때문에 그렇게 느끼는 거였겠지만 말이다.', '', '오피스텔에 기본 옵션으로 있는 테이블에 셋이 둘러앉아 2차를 시작했다.', '물론 Y에게만 2차였고, K와 나는 소고기부터 아이스크림, 술집까지 다녀왔으니 4차였다.', '그래서인지 이쯤부터는 취해서 무슨 대화를 나눴는지 정확히 기억나지 않는다.', '이 날 하룻동안 마신 위스키가 6잔은 되는 것 같으니까.', '아마 굳이 기억하지 않아도 되는 소소한 이야기들이긴 했을 거다.', '많이 취했다는 걸 스스로도 알면서도 왠지 묘하게 기분 좋고 즐거워서 K의 집까지 오게 된 거니까.', '', '밤 12시경 전철이 끊긴 시간, 집으로 돌아가는 택시 안에서 길었던 하루를 돌아봤다.', '오후 3시에 만나서 12시에 헤어졌으니 9시간을 밖에서 돌아다녔다.', '그것도 남대문에서 망원동, 망원동에서 K의 집, 그리고 다시 우리 동네까지.', 'K와 보낸 이 하루는 그동안 다른 사람들과 경험해본 적 없는 묘한 만남이었다.', '어색하진 않지만 아주 친하지도 않은 연상의 남자와 하루 종일 함께 다니며 꽤 많은 대화를 나눴다.', 'K의 학창시절과 우여곡절 끝에 대학에 간 이야기부터, 내가 이혼하는 과정에서 겪은 일들과 다른 모임에서 만났던 독특한 사람들과의 에피소드도.', '', '지난 예술의전당 벙개 때도 그랬지만, K와 대화를 나눌 때면 큰 거부감이나 조심스러움 없이 솔직한 대화를 나누게 된다.', '아마 그가 누구를 대하든 똑같이 솔직하게 대하기 때문이란 생각이 들었다.', '그리고 내가 어떤 이야기를 하든 오해하거나 편견을 가지고 받아들이지 않고 있는 그대로 받아들이는 사람이라는 걸 어느새 내가 느끼고 있었던 것 같다.', '', '6월치고는 많이 덥고 습했던 날씨에 바쁘게 돌아다니며 보낸 하루가 피곤했던 날로 기억되지 않고, 예상치 못한 즐거운 여행으로 남게 될 것 같아 기분이 제법 좋았다.', ' ', 'K와의 관계가 왠지 조금 달라지고 있다는 느낌과 함께 가만히 택시 안에서 흘러나오는 라디오를 들으며 눈을 감았다.', '너무 귀여웠던 젤라또', '*매주 목요일 <우리 종착지가 사랑이 아니라면> 연재', '*책 <손을 꼭 잡고 이혼하는 중입니다>와 일부 이어지는 조니워커 시리즈입니다.', '*하지만 앞의 이야기를 읽지 않으셔도 아무 문제가 없습니다.', '[서울 강연 안내]', '일시 : 10월 22일 (일) 10시~12시 30분', '장소 : 세첸코리아 (서울특별시 종로구 사직로 101 필운빌딩 7층)', '비용 : 1만원', '참가신청 : 링크 클릭-> 구글폼 '], 'tgt_txt': 'none'}]\n"
     ]
    }
   ],
   "source": [
    "# 인풋 데이터 POS 태깅 \n",
    "import json\n",
    "from kiwipiepy import Kiwi\n",
    "crawled = json.load(open(\"../crawled_data/result (16).json\"))[\"content\"]\n",
    "kiwi = Kiwi(num_workers = 6)\n",
    "postagged = list()\n",
    "tokenize_list = list(kiwi.tokenize(crawled))\n",
    "for sen in tokenize_list:\n",
    "    sen_pos = list()\n",
    "    for char in sen:\n",
    "        token = char.form + \"/\" + char.tag\n",
    "        sen_pos.append(token)\n",
    "    postagged.append(sen_pos)\n",
    "    \n",
    "# bert 인풋으로 가공\n",
    "news = format_to_dict(postagged, crawled)\n",
    "print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoder': 'transformer', 'mode': 'summary', 'bert_data_path': '/home/dongwon/korbertsum/bert_data/korean', 'model_path': '/home/dongwon/korbertsum/models/bert_classifier', 'bert_model': '/home/dongwon/001_bert_morp_pytorch', 'result_path': '/home/dongwon/korbertsum/results/korean', 'temp_dir': '.', 'bert_config_path': '/home/dongwon/001_bert_morp_pytorch/bert_config.json', 'batch_size': 1000, 'use_interval': True, 'hidden_size': 128, 'ff_size': 512, 'heads': 4, 'inter_layers': 2, 'rnn_size': 512, 'param_init': 0, 'param_init_glorot': True, 'dropout': 0.1, 'optim': 'adam', 'lr': 0.002, 'report_every': 1, 'save_checkpoint_steps': 5, 'block_trigram': True, 'recall_eval': False, 'accum_count': 1, 'world_size': 1, 'visible_gpus': '-1', 'gpu_ranks': '0', 'log_file': '/home/dongwon/korbertsum/logs/bert_classifier', 'test_from': '/home/dongwon/korbertsum/models/bert_classifier/model_step_40000.pt'}\n",
      "gpu_rank 0\n",
      "고기를 먹은 다음 단 음식이라니, 이 사람이 뭘 좀 아는군 싶어서 마음에 들었다.<q>더위를 가시게 해줄 시원한 하이볼 2잔을 주문하고, 화로에 소고기를 한 점씩 올려 구워 먹으며 이런 저런 이야기를 나눴다.<q>각자 구매한 위스키를 들고 K의 차에 타며 이제 어디를 갈까 얘기를 나눴다. none\n",
      "\n",
      "고기를 먹은 다음 단 음식이라니, 이 사람이 뭘 좀 아는군 싶어서 마음에 들었다.<q>더위를 가시게 해줄 시원한 하이볼 2잔을 주문하고, 화로에 소고기를 한 점씩 올려 구워 먹으며 이런 저런 이야기를 나눴다.<q>각자 구매한 위스키를 들고 K의 차에 타며 이제 어디를 갈까 얘기를 나눴다.\n"
     ]
    }
   ],
   "source": [
    "summary_result = summary(args, news, 0, \"\", None)[0]\n",
    "print()\n",
    "print(summary_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
